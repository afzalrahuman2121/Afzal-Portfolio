<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    <title>Data Science Internship @ Avasoft</title>
    <link href="styles.css" rel="stylesheet">
</head>
<body>

    <header>
        <h1>Data Science Internship @ Avasoft</h1>
        <nav>
            <a href="index.html">Home</a>
        </nav>
    </header>

    <section class="internship-details">
        <h2>Internship Overview</h2>
        <p>
            <strong>Company:</strong> Avasoft <br>
            <strong>Position:</strong> Data Science Intern <br>
            <strong>Duration:</strong> December 2023 - April 2024
        </p>
    
        <h3>Key Responsibilities & Tools Used</h3>
    
        <ul>
            <li><strong>Data Solutions Development:</strong> I built and optimized <strong>data pipelines</strong> and <strong>data warehousing solutions</strong> to manage high volumes of data. I worked extensively with tools like:
                <ul>
                    <li><strong>SQL:</strong> Wrote complex queries to manage and retrieve data from relational databases.</li>
                    <li><strong>Azure Synapse Analytics:</strong> Integrated large datasets into the Synapse environment for fast data queries and analysis.</li>
                    <li><strong>SSIS (SQL Server Integration Services):</strong> Automated ETL processes, ensuring efficient data flow across the system.</li>
                    <li><strong>Databricks:</strong> Used Apache Spark clusters to process large-scale data efficiently.</li>
                    <li><strong>PostgreSQL:</strong> Managed relational data with performance-optimized queries.</li>
                </ul>
            </li>
    
            <li><strong>Data Analysis & Analytics:</strong> Conducted in-depth data analysis using:
                <ul>
                    <li><strong>Python:</strong> Implemented data processing scripts using Pandas and NumPy to clean, analyze, and manipulate datasets.</li>
                    <li><strong>Pandas:</strong> Applied Pandas for extensive data manipulation and transformation.</li>
                    <li><strong>Apache Spark:</strong> Leveraged Spark for distributed data processing, enabling quick transformations on massive datasets.</li>
                    <li><strong>Power BI:</strong> Created interactive dashboards and visualizations to present insights from the data analysis effectively.</li>
                </ul>
            </li>
    
            <li><strong>Project Development:</strong> Led the development of a comprehensive project that utilized various <strong>data engineering methodologies</strong>:
                <ul>
                    <li>Applied <strong>best practices</strong> in data management, ensuring clean data processing and storage mechanisms.</li>
                    <li>Collaborated with teams to gather <strong>business requirements</strong> and translate them into technical solutions.</li>
                    <li>Built reusable <strong>ETL pipelines</strong> for data extraction, transformation, and loading, optimizing the process for better performance and scalability.</li>
                </ul>
            </li>
    
            <li><strong>ETL Process Expertise:</strong> Gained expertise in <strong>ETL (Extract, Transform, Load)</strong> processes:
                <ul>
                    <li>Built efficient <strong>ETL pipelines</strong> using <strong>SSIS</strong> and <strong>Python</strong>, automating data loading processes to and from cloud storage.</li>
                    <li>Performed data cleaning, transformation, and preparation tasks on large datasets to ensure high-quality data ingestion.</li>
                </ul>
            </li>
    
            <li><strong>Documentation & Requirements Gathering:</strong> Created:
                <ul>
                    <li>Detailed <strong>Functional Requirement Documents (FRD)</strong> outlining project objectives and business requirements.</li>
                    <li>Comprehensive <strong>design documents</strong> for technical solutions, ensuring alignment with the overall project architecture.</li>
                </ul>
            </li>
    
            <li><strong>Cloud Data Storage (Azure Data Lake Storage - ADLS):</strong> Managed large volumes of data in a cloud environment using:
                <ul>
                    <li><strong>ADLS (Azure Data Lake Storage):</strong> Designed efficient data models to store unstructured and structured data in the lake, ensuring faster data retrieval.</li>
                    <li>Optimized storage and processing workflows to handle both structured and semi-structured data types effectively.</li>
                </ul>
            </li>
        </ul>
    </section>
    

    <footer>
        <p>&copy; 2024 Afzal Rahuman. All rights reserved.</p>
    </footer>

</body>
</html>
